**How SayVeritas Works**: The Centaur Model for Human-AI Collaboration
**Introduction**: Shifting from Answer-Checking to Authentic Assessment
Generative AI has broken traditional written assessment, leaving educators to grade work they can no longer trust. Judging a student's knowledge from a generative AI-polished essay is like judging a chef by a photograph of their meal—it’s a perfect image that proves nothing. An oral assessment, however, is like being in the kitchen with the chef; it reveals the authentic, un-fakeable process of thinking. SayVeritas is built on this principle, leveraging a "Centaur" model of human-AI collaboration where the educator's expertise guides the AI's efficiency.This human-in-the-loop framework, substantiated by research from Riedl & Weidmann (2025), creates a powerful synergy between teacher and technology. The strategic importance of this model is threefold: it restores academic integrity by requiring students to articulate their knowledge spontaneously; it saves teachers significant time on grading; and it assesses the "hidden curriculum" of oral reasoning, which reveals a much deeper level of understanding than written formats can capture. This process is built on a powerful yet simple four-step cycle designed to empower both educators and learners.Step 1: Teacher Design → Step 2: Student Execution → Step 3: AI Analysis → Step 4: Teacher ValidationThis document breaks down each step of this collaborative process, showing how SayVeritas unbundles the teacher's role to focus on what matters most: insightful instruction and genuine student mastery.
1. **Step 1**: Teacher Design - The Educator as the Architect
The SayVeritas "Centaur" model begins with the educator’s professional judgment, placing them firmly in the role of architect for every assessment. This ensures that all evaluations are grounded in specific learning objectives and sound pedagogical standards, rather than generic, automated prompts. SayVeritas puts educators in complete command of the assessment design, using the intuitive  Question Builder  to create meaningful tasks.Teachers can craft assessments using several methods:
**Manual Entry**: Directly typing in custom questions tailored to their specific lesson or unit.
**AI Generation**: Providing a learning objective and allowing the AI to draft relevant questions, which the teacher then reviews and refines.
**Document Upload**: Uploading a PDF or image—such as a primary source document, a scientific diagram, or a data chart—for students to analyze orally.
**Question Bank**: Importing professionally vetted questions from a vast library, sortable by subject, grade level, and Bloom's Taxonomy level.Crucially, the teacher also defines the standards for success by configuring the platform's  Dual Rubric Scoring  system. This system deploys two specialized AI agents, each focused on a different dimension of student thinking:
**Agent Alpha**: Evaluates  Reasoning & Synthesis , assessing the logic, structure, and critical thinking demonstrated in the response.
**Agent Beta**: Evaluates  Evidence & Accuracy , assessing the factual correctness, use of specific details, and terminology.**SUGGESTION**: Insert a simple icon or graphic here representing 'Teacher Control' or 'Architecting an Assessment'.By establishing the questions and the criteria for success, the teacher sets the stage for a valid and reliable assessment, seamlessly transitioning the process from design to execution.
2. **Step 2**: Student Execution - A Safe Space for Authentic Reasoning
The student experience is strategically designed to foster genuine thought while minimizing the "evaluative anxiety" that often accompanies live performance. The asynchronous recording environment provides a solution to the "fight-or-flight" response that can inhibit a student's ability to think clearly. In this controlled setting, students are tasked with recording a spontaneous oral response, an act of active participation that directly mitigates the risk of "superficial learning" associated with passive AI use, as identified by Delikoura et al. (2025).This digital  "safe space"  for learning is validated by research from Heinz et al. (2025), which found that users engaged more freely with an AI partner precisely because, in the words of the lead researcher, “it won’t judge them.” This psychological safety encourages students to practice more freely, take intellectual risks, and build confidence without the fear of making mistakes in front of their peers. They can focus purely on articulating their understanding, knowing the goal is to show their thinking process, not to achieve a flawless performance.**SUGGESTION**: Insert a simple icon or graphic here representing a 'Student Recording on a Device' or a 'Safe Space Shield'.Once the student has recorded and submitted their response, their active role is complete, and the platform’s AI begins its efficient and transparent analysis.
3. **Step 3**: AI Processing - Efficient, Transparent, and Research-Backed Analysis
In this step, the AI acts not as a final judge, but as a highly efficient assistant. Its purpose is to handle the most time-intensive and repetitive aspects of assessment—transcription and initial scoring—freeing the educator to focus on higher-level evaluation and feedback. The AI processing pipeline is built on best-in-class technology to ensure reliability and transparency.The analysis occurs in two primary stages:
**High-Fidelity Transcription**: The platform utilizes  OpenAI Whisper  to convert the student's spoken audio into text. It achieves over 95% transcription accuracy  in ideal conditions , creating a reliable text version of the student’s spoken response that serves as the foundation for the subsequent analysis.
**Nuanced, Rubric-Based Scoring**: Using OpenAI ChatGPT, the platform performs the initial scoring against the teacher-defined rubric. It maintains the  Dual-Agent AI  approach, where "Agent Alpha" assesses  Reasoning & Synthesis  and "Agent Beta" assesses  Evidence & Accuracy , providing a multi-faceted and balanced initial evaluation.For every score it suggests, the AI also generates a clear justification, complete with specific quotes and timestamps pulled directly from the student's response. This transparency is central to the platform’s credibility, as it allows the teacher to see exactly  why  the AI arrived at its conclusion, setting the stage for the final and most important step in the process.
4. **Step 4**: Teacher Validation - The Final Authority on Mastery
The process culminates with the teacher, reinforcing their ultimate authority and completing the "Centaur" collaboration loop. The AI provides data and suggestions, but the teacher’s professional expertise serves as the final and definitive measure of student understanding. The Teacher Review Dashboard transforms validation from a chore into a moment of deep instructional insight, making the process remarkably efficient.From the dashboard, the teacher can perform several key actions:
**Review AI-Generated Scores**: Quickly see the AI’s rubric-based scores and read the evidence-backed justifications for each.
**Listen and Read Simultaneously**: Play back the student's audio recording at up to  2x speed  while following along with the synchronized transcript, allowing for rapid and thorough review.
**Make the Final Judgment**: Accept the AI’s suggested score with a single click or easily override it with their own evaluation and personalized comments.This streamlined workflow empowers educators to review an entire class set of oral responses in under an hour, reclaiming upwards of  20 hours per semester  previously lost to the manual grading of essays. By automating the repetitive elements of grading, teachers can reinvest their time in high-impact activities like student mentorship, small-group instruction, and lesson planning.**SUGGESTION**: Insert a screenshot or mockup of the Teacher Review Dashboard, highlighting the AI score suggestion next to the teacher's final grade input field.With the teacher’s final validation, the Human-AI collaborative cycle is complete, delivering an assessment that is authentic, efficient, and fully controlled by the educator.
**Conclusion**: The SayVeritas Outcome - Deeper Learning, Reclaimed Time, and True Integrity
The SayVeritas four-step process represents a fundamental shift in how we approach assessment. By blending the irreplaceable expertise of the educator with the scalable efficiency of AI, this "Centaur" model delivers a powerful outcome for modern classrooms. It moves evaluation beyond simple answer-checking to capture the dynamic, real-time process of student thinking. The ultimate value of this collaborative approach can be distilled into three core benefits for educators.
**Authentic Understanding**: SayVeritas moves beyond rote memorization to assess how students truly think, reason, and articulate their knowledge. It provides a clear window into their thought processes, revealing a depth of understanding that written tests often obscure.
**Unparalleled Efficiency**: By automating the most time-consuming aspects of grading, teachers can save upwards of 20 hours per semester. This reclaimed time empowers educators to focus on what they do best: teaching, mentoring, and inspiring their students.
**Restored Academic Integrity**: SayVeritas doesn't just catch cheating; it makes it irrelevant, creating a new gold standard for assessment where the process of thinking is finally more valuable than the polished final answer.
